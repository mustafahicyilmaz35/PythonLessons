{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsFW3ItLrzxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3627ecea-c88d-4f7f-9286-ad9f33776985"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten   #Flatten çok boyutlu dizileri tek boyuta indirmek için kullanılır.\n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255\n",
        "x_train = x_train.reshape(60000,28,28,1) #Bir fazla boyutu tensor için kullandık.\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten()) #modele gelen çok boyutlu dizileri tek boyuta indirmek için kullanılan keras kütüphanesi\n",
        "model.add(Dense(784,activation = 'sigmoid')) #mnist ten gelen veriler 28x28 boyutunda geliyor. Tek boyutlu kullanabilmek için Dense in içine 784 olarak gönderdik\n",
        "model.add(Dense(100,activation = 'sigmoid'))\n",
        "model.add(Dense(100, activation = 'sigmoid'))\n",
        "model.add(Dense(10,activation = 'sigmoid')) #Giren sınıf sayısı kadar çıktı almalıyız. 10 tane girdi sınıfımız olduğu için 10 tane çıktı alıyoruz.\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=1)\n",
        "\n",
        "model.predict(x_test[0].reshape(1,28,28,1))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 20s 340us/step - loss: 0.4111 - accuracy: 0.8896 - val_loss: 0.1668 - val_accuracy: 0.9506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.6373734e-04, 7.6916607e-05, 1.1639893e-03, 3.6495924e-04,\n",
              "        7.9466801e-05, 5.6412344e-05, 2.8501149e-06, 4.4853237e-01,\n",
              "        7.3651034e-05, 5.6906685e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}